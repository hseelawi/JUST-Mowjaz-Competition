{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fifteen-hampshire",
   "metadata": {},
   "source": [
    "## BiLSTM with ARAVEC\n",
    "In this notebook, we will walk you through the process of reproducing the BiLSTM with ARAVEC baseline for the Multi-label classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-queen",
   "metadata": {},
   "source": [
    "### Loading Required Modules\n",
    "First off, we start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score, jaccard_score\n",
    "\n",
    "from embed_classer import embed\n",
    "from utils import normalize_text, create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-passport",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../Data/train.tsv', sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"../Data/validation.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../Data/test_unlabaled.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-harvest",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-container",
   "metadata": {},
   "source": [
    "And the 5 first entries in the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-rebecca",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-breakdown",
   "metadata": {},
   "source": [
    "### Model Preparation\n",
    "We start by setting the randomisation seed and the maximum sentence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 32\n",
    "tf.random.set_seed(seed_val)\n",
    "max_sentence_len = 256\n",
    "\n",
    "# Load Aravec \n",
    "embedd_path = '../models/full_uni_sg_300_twitter.mdl'\n",
    "embedd_size = 300\n",
    "\n",
    "# Save Model\n",
    "model_path = '../models/bi_lstm.best.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-uganda",
   "metadata": {},
   "source": [
    "Next we load our embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embed(embedd_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-replication",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([normalize_text(text) for text in df_train.Article.values])\n",
    "Y_train = df_train[df_train.columns[1:]].values\n",
    "\n",
    "X_dev = np.array([normalize_text(text) for text in df_dev.Article.values])\n",
    "Y_dev = df_dev[df_dev.columns[1:]].values\n",
    "\n",
    "X_train = embedder.embed_batch(X_train, max_sentence_len)\n",
    "X_dev = embedder.embed_batch(X_dev, max_sentence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-render",
   "metadata": {},
   "source": [
    "Then we define the callbacks for EarlyStopping and ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-gambling",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(max_sentence_len, embedd_size)\n",
    "history = model.fit(X_train,\n",
    "          Y_train,\n",
    "          epochs=5\n",
    "          batch_size=32,\n",
    "          validation_data = (X_dev, Y_dev),\n",
    "          callbacks=[checkpoint_callback, earlystopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-hepatitis",
   "metadata": {},
   "source": [
    "We calculate the F1-Score and Jaccard score for the development set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_dev) > 0.5\n",
    "\n",
    "print(\"F1 macro:   {}\".format(round(f1_score(Y_dev, preds, average=\"macro\"), 3)))\n",
    "print(\"F1 micro:   {}\".format(round(f1_score(Y_dev, preds, average=\"micro\"), 3)))\n",
    "print(\"F1 samples: {}\".format(round(f1_score(Y_dev, preds, average=\"samples\"), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_samples = jaccard_score(Y_dev, preds, average=\"samples\")\n",
    "jaccard_macro = jaccard_score(Y_dev, preds, average=\"macro\")\n",
    "jaccard_micro = jaccard_score(Y_dev, preds, average=\"micro\")\n",
    "\n",
    "print(\"Jaccard Macro Score:         {}\".format(round(jaccard_macro, 3)))\n",
    "print(\"Jaccard Micro Score:         {}\".format(round(jaccard_micro, 3)))\n",
    "print(\"Jaccard samples Score:       {}\".format(round(jaccard_samples, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-photography",
   "metadata": {},
   "source": [
    "### Submission Preperation\n",
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([normalize_text(text) for text in df_test.Article.values])\n",
    "X_test = embedder.embed_batch(X_test, max_sentence_len)\n",
    "preds = model.predict(X_test) > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-community",
   "metadata": {},
   "source": [
    "Next we save the predictions into a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=preds, index=None, columns=None, dtype=int)\n",
    "df.to_csv(\"../Data/outputs/answer.tsv\", header=False, index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
