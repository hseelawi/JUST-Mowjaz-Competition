{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We start by importing the needed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data\n",
    "**Article column** represents the text that we want to classify.<br>\n",
    "**next 10 coumns** represent labels for each article ['فن ومشاهير','أخبار','رياضة','اقتصاد','تكنولوجيا',\n",
    " 'اسلام و أديان','سيارات','طقس','منوعات أخرى','صحة','مطبخ']. For each article we have binary list consist of 10 item mapped to our labels each item either \" *0* \" means that we couldn't assign this class for the article \" *1* \" means that we could assign this class for the article.<br>\n",
    "**topics_number** represents the number of label that we assign for every article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../Data/\"\n",
    "train_df = pd.read_csv(data_folder_path+\"train.tsv\",sep=\"\\t\")\n",
    "validation_df = pd.read_csv(data_folder_path+\"validation.tsv\",sep=\"\\t\")\n",
    "testing_df = pd.read_csv(data_folder_path+\"test_unlabaled.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the first five rows of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of the validation data\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of the testing data\n",
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF\n",
    "TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: **how many times a word appears in a document**, and the **inverse document frequency of the word across a set of documents**.<br>\n",
    "given word *t* and document *d* from set of documents *D* and *N* is the total number of documents in the corpus we calculate **tf-id** as follows:\n",
    "\n",
    "$$tfidf(t,d,D) = tf(t,d).idf(t,D)$$\n",
    "where:\n",
    "$$tf(t,d) = log(1+freq(t,d))$$\n",
    "$$idf(t,D) = log(\\frac{N}{count(d\\in D:t \\in d )})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise tfidf vectoriser object\n",
    "tfidf = TfidfVectorizer(analyzer='word', max_features=10000, ngram_range=(1,3))\n",
    "#alocate X and Y values for training,validation and testing sets\n",
    "X_train = train_df.iloc[:,0]\n",
    "y_train = train_df.iloc[:,1:]\n",
    "X_validation = validation_df.iloc[:, 0]\n",
    "y_validation = validation_df.iloc[:,1:]\n",
    "X_test = testing_df.iloc[:,0]\n",
    "print(\"training shapes: Features {}, labels {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Validation shapes: Features {}, labels {}\".format(X_validation.shape, y_validation.shape))\n",
    "print(\"Testing shape: Features {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we extract the tf-idf features for the training and validation datasets, and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the model \n",
    "svc = LinearSVC()\n",
    "#extract tfidf feature vector from taining data\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "#extract tfidf feature vector from calidation data\n",
    "X_validation = tfidf.transform(X_validation)\n",
    "# train the model on training data\n",
    "clf = OneVsRestClassifier(svc)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on validation and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we evaluate the performance of our model on the validation data, using Jaccard and F1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = clf.predict(X_validation)\n",
    "print(\"validation jaccard sample: {}, f1_score sample:{}\".\n",
    "      format(jaccard_score(y_validation, y_val_pred, average=\"samples\"),\n",
    "             f1_score(y_validation, y_val_pred, average=\"samples\")))\n",
    "print(\"validation jaccard macro: {}, f1_score macro:{}\".\n",
    "      format(jaccard_score(y_validation, y_val_pred, average=\"macro\"),\n",
    "             f1_score(y_validation, y_val_pred, average=\"macro\")))\n",
    "print(\"validation jaccard micro: {}, f1_score micro:{}\".\n",
    "      format(jaccard_score(y_validation, y_val_pred, average=\"micro\"),\n",
    "             f1_score(y_validation, y_val_pred, average=\"micro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving\n",
    "\n",
    "Below we save the needed files to use later in our API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf, '../models/tfidf_vectorizer.pkl',compress=6)\n",
    "joblib.dump(clf,\"../models/svc.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first extract tfidf feature vector for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the labels for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we save the outputs as a tsv file ready for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=preds, index=None, columns=None)\n",
    "df.to_csv(\"../Data/outputs/answer.tsv\", header=False, index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
